{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantische Ähnlichkeit von Texten\n",
    "\n",
    "Natürliche Sprachen bieten uns mannigfaltige Möglichkeiten, dieselben Inhalte auf unterschiedliche Art und Weise auszudrücken. Für die Interpretation natürlichsprachlicher Texte reicht es daher nicht, auf den Ebenen von Morphologie und Syntax zu bleiben und die Form von Wörtern sowie deren Anordnung im Satz zu betrachten, sondern wir müssen als zusätzliche Ebene die der Semantik betrachten.\n",
    "\n",
    "Dabei beginnen wir zunächst mit der Betrachtung der Wortebene und sammeln Erfahrung mit word2vec.\n",
    "\n",
    "Anschließend wollen wir versuchen, von Wort- zu Satzbedeutungen zu kommen: Wie gut können wir die Ähnlichkeit zweier Sätze unter Rückgriff auf die semantischen Embeddings der in ihnen enthaltenen Wörter bestimmen?\n",
    "\n",
    "Als Orientierung dient uns dabei das [STS-Benchmark-Datenset](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark), das im Rahmen von [SemEval](https://en.wikipedia.org/wiki/SemEval) entstanden ist.\n",
    "Das Datenset enthält Trainings-, Test- und Evaluationsdaten zu folgender Aufgabenstellung: \n",
    "Gegeben zwei Sätze S1 und S2, berechne Ähnlichkeitswert zwischen 0 (völlig unterschiedlicher Inhalt) und 5 (bedeutungsgleich)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1: Word2Vec\n",
    "> You shall know a word by the company it keeps.\n",
    ">\n",
    "> -- <cite>J. R. Firth</cite>\n",
    "\n",
    "Im ersten NLP-Labor haben wir mit dem Bag-of-Words-Modell eine recht einfache Methode festgestellt, um Wörter bzw. ganze Sätze in einen Vektorraum abzubilden: Jedem Wort wird ein eindeutiger Index zugewiesen. Es lässt sich dann als one-hot-enkodierter Vektor darstellen, der an eben jenem Index eine Eins und ansonsten nur Nullen enthält und dessen Länge der Anzahl der Wörter im Vokabular entspricht. Die Enkodierung ganzer Sätze erhält man durch Aufsummieren dieser one-hot-enkodierten Vektoren.\n",
    "Bei einem solchen Modell geht auf Satzebene die Information über die Reihenfolge der Wörter verloren und ganz allgemein wird offensichtlich die Semantik der Wörter nicht berücksichtigt.\n",
    "\n",
    "Gehen wir zum Beispiel von folgendem Vokabular aus: ```{\"heiß\", \"warm\", \"Gurke\"}``` und enkodieren die einzelnen Wörter wie folgt: ```[1, 0, 0], [0, 1, 0], [0, 0, 1]```, dann sind sich \"heiß\" und \"warm\" genauso ähnlich oder unähnlich wie \"heiß\" und \"Gurke\".\n",
    "\n",
    "Semantische Embeddings schaffen an dieser Stelle Abhilfe. Ein bekannter Vertreter dieser Ansätze ist das Word2Vec-Modell, das 2013 von [Tomas Mikolov et al.](https://arxiv.org/abs/1301.3781) bei Google entwickelt wurde und seither rasch an Verbreitung gewonnen hat.\n",
    "\n",
    "Wir werden mit vortrainierten Google-News-Embeddings arbeiten, die [hier](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing) heruntergeladen werden können. Die Vektoren haben die Länge 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1.1: Vorbereitung\n",
    "Ladet die Embeddings über den oben angegebenen Link herunter und verwendet gensim, um sie zu laden.\n",
    "\n",
    "**Hinweis**: Kann einen Moment dauern, bis das Dictionary, das von Wort auf Embedding abbildet, erzeugt ist. Im Zweifel ein ```limit``` angeben und nur die ersten 1,5 Mio. Embeddings laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "embeddings = gensim.models.KeyedVectors.load_word2vec_format(#TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_embeddings(embeddings):\n",
    "    error_message = \"Oh, da ist wohl etwas schiefgelaufen! Der folgende Test schlägt fehl: {}.\"\n",
    "    most_similar = embeddings.most_similar(positive=['man', 'queen'], negative=['woman'])\n",
    "    if len(most_similar) < 1 or most_similar[0][0] != 'king':\n",
    "        return error_message.format(\"'Most similar'\")\n",
    "\n",
    "    doesnt_match = embeddings.doesnt_match(['spring', 'rain', 'autumn', 'summer'])\n",
    "    if doesnt_match != 'rain':\n",
    "        return error_message.format(\"'Doesn't match'\")\n",
    "    \n",
    "    most_similar_to_given = embeddings.most_similar_to_given('school', ['cat', 'sound', 'university', 'whine'])\n",
    "    if most_similar_to_given != 'university':\n",
    "        return error_message.format(\"'Most similar to given'\")\n",
    "    \n",
    "    return \"Sieht gut aus.\"\n",
    "\n",
    "check_embeddings(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1.2: Spaß mit Semantik\n",
    "Im Folgenden wollen wir uns ein bisschen mit dem Mehrwert beschäftigen, den semantische Embeddings bieten.\n",
    "\n",
    "Mit ihnen lassen sich zum Beispiel folgende Fragen beantworten:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welche Stadt ist das New York Deutschlands? (Hinweis: 'New_York' ist als Token in den Embeddings enthalten)\n",
    "print('Das deutsche New York ist: {}'.format(#TODO))\n",
    "\n",
    "# Wer ist eigentlich der Mozart der Physik?\n",
    "print('Der Mozart der Physik ist: {}'.format(#TODO))\n",
    "\n",
    "# Welches Wort verhält sich zu 'singing' wie 'burnt' zu 'burning'?\n",
    "print('burning:burnt wie singing:{}'.format(#TODO))\n",
    "\n",
    "# Sind sich Deutschland und Frankreich ähnlicher oder Deutschland und Kanada?\n",
    "print('Ähnlichkeit DE, FR: {}'.format(#TODO))\n",
    "print('ähnlichkeit DE, CAN: {}'.format(#TODO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Interpretation der Ergebnisse ist jedoch Vorsicht geboten: Es werden zwar semantische Beziehungen abgebildet, aber die entsprechen möglicherweise nicht immer den Erwartungen.\n",
    "\n",
    "Wie ähnlich sind sich zum Beispiel \"Leben\" und \"Tod\", \"kalt\" und \"warm\", \"Norden\" und \"Süden\"?\n",
    "\n",
    "Sind die Ergebnisse wie erwartet? Warum (nicht)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Embeddings sind nicht neutral, sondern spiegeln die Beziehungen wieder, die sich in den Trainingsdaten finden lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wird Wissenschaft von Frauen oder Männern gemacht?\n",
    "print('Wissenschaft wird gemacht von: {}'.format(#TODO))\n",
    "# Sind Mörder eher Schwarze, Weiße oder Asiaten?\n",
    "print('Mörder sind: {}'.format(#TODO))\n",
    "# Was bleibt vom Mann, wenn die Intelligenz abgezogen wird?\n",
    "print('Mann ohne Intelligenz: {}'.format(#TODO))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2: Von Wörtern zu Sätzen\n",
    "Nachdem wir uns mit der semantischen Repräsentation von Wörtern beschäftigt haben, wollen wir jetzt zu Sätzen übergehen. Wie bereits gesagt, wollen wir die Ähnlichkeit von Satzpaaren bestimmen. Dazu brauchen wir einen Testdatensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2.1: Testdaten einlesen\n",
    "Die Datei ```sts-train.csv``` enthält 5749 Satzpaare, deren Ähnlichkeit jeweils mit einem Score zwischen 0 (völlig unähnlich) und 5 (völlig ähnlich) bewertet wurde. Lest diese Datei in einen Pandas-Dataframe ein.\n",
    "\n",
    "Zu beachten sind die folgenden Punkte:\n",
    "* Bei den CSV-Dateien handelt es sich eigentlich strenggenommen um TSV-Dateien, d.h. die einzelnen Spalten sind durch Tab getrennt.\n",
    "* Einige Zeilen enthalten unvollständige Quotes, die zu Fehlern beim Einlesen führen können. Diese sollen ignoriert werden. (```quoting=csv.QUOTE_NONE```)\n",
    "* Zitat aus der zum Datenset gehörigen README: \n",
    ">Each file is encoded in utf-8 (a superset of ASCII), and has the following tab separated fields:  \n",
    ">__genre filename year score sentence1 sentence2__  \n",
    ">optionally there might be some license-related fields after sentence2.\n",
    "\n",
    "Neben den uns interessierenden Spalten \"score\", \"sentence1\" und \"sentence2\" sind also noch weitere Spalten enthalten. Wir können den Parameter ```usecols``` verwenden, um die Indizes der uns interessierenden Spalten anzugeben (Zählung beginnt bei 1). Für die Spalten vergeben wir die Namen \"score\", \"sentence1\" und \"sentence2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "testdata =  #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2.2: Semantische Repräsentation von Sätzen\n",
    "Genau wie für Wörter wollen wir auch die Semantik von Sätzen in einem Vektor der Dimension 300 abbilden. Dazu wählen wir einen recht einfachen Ansatz und mitteln die Vektoren der Wörter, aus denen der Satz besteht.\n",
    "\n",
    "Schreibt eine Funktion, die einen Satz entgegennimmt und einen Vektor mit den gemittelten semantischen Embeddings zurückgibt. Wird ein leerer String übergeben oder enthält der übergebene Satz nur Wörter, für die keine Embeddings vorhanden sind, soll ein Nullvektor der Länge 300 zurückgegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "    \n",
    "def sentence_to_vec(sentence):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vec_tests():\n",
    "    if (np.zeros(300) != sentence_to_vec('')).any():\n",
    "        return \"Bei leerer Eingabe soll ein Nullvektor zurückgegeben werden\"\n",
    "    if (np.zeros(300) != sentence_to_vec('thereisnosuchword')).any():\n",
    "        return \"Wenn keine Embeddings gefunden werden, soll ein Nullvektor zurückgegeben werden.\"\n",
    "    if (embeddings['word'] != sentence_to_vec('word')).any():\n",
    "        return \"Da stimmt was nicht.\"\n",
    "    if ((embeddings['cat'] + embeddings['dog']) / 2 != sentence_to_vec('cat dog')).any():\n",
    "        return \"Die Funktion soll den Durchschnittswert der Vektoren berechnen.\"\n",
    "    if (embeddings['word'] != sentence_to_vec('thereisnosuchword word')).any():\n",
    "        return \"Wörter, deren Embedding nicht bekannt ist, sollen nicht berücksichtigt werden.\"\n",
    "    return \"Grundlegende Tests bestanden.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentence_to_vec_tests())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2.3: Ähnlichkeitsberechnung\n",
    "Um die Ähnlichkeit zweier Vektoren zu bestimmen, wird häufig die [Kosinusähnlichkeit](https://de.wikipedia.org/wiki/Kosinus-%C3%84hnlichkeit) verwendet. Diese kann Werte zwischen −1 (Vektoren sind genau entgegengerichtet) und 1 (Vektoren sind genau gleichgerichtet) annehmen. Weil wir die von uns berechneten Ähnlichkeitswerte aber mit denen der Testdaten vergleichen können wollen, müssen wir den Wertebereich so anpassen, dass wir Werte zwischen 0 und 5 erhalten. Dabei treffen wir die vereinfachende Annahme, dass eine Kosinusähnlichkeit kleiner-gleich 0 als unähnlich (Wert 0) zu werten ist.\n",
    "\n",
    "Schreibt eine Funktion, die zwei Sätze entgegennimmt und Ähnlichkeitswerte im Bereich ```[0, 5]``` zurückgibt, basierend auf der Kosinusähnlichkeit der semantischen Vektoren der Sätze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def compute_similarity_score(sentence_1, sentence_2):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def compute_similarity_score_test():\n",
    "    if not (math.isclose(compute_similarity_score(\"hot dog\", \"hot dog\"), 5.0)):\n",
    "        return \"Identische Sätze sollten einen Ähnlichkeitswert von 5 haben.\"\n",
    "    if not (math.isclose(compute_similarity_score(\"dog hot\", \"hot dog\"), 5.0)):\n",
    "        return \"Sätze, die sich nur in der Anordnung der Wörter unterscheiden, sollten einen Ähnlichkeitswert von 5 haben.\"\n",
    "    if not (math.isclose(compute_similarity_score(\"nosuchword\", \"word\"), 0.0)):\n",
    "        return \"Der Vergleich eines unbekannten Wortes mit einem bekannten, sollte zu einem Ähnlichkeitswert von 0 führen.\"\n",
    "    if (math.isclose(compute_similarity_score(\"bread\", \"cake\"), 0.0)):\n",
    "        return \"Verwandte Worte sollten einen Ähnlichkeitswert größer Null aufweisen.\"\n",
    "    return \"Grundlegende Tests bestanden.\"\n",
    "\n",
    "compute_similarity_score_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3: Validierung\n",
    "Im letzten Schritt wollen wir bestimmen, wie gut unsere Ähnlichkeitsberechnung funktioniert, d.h. wie stark die von uns berechneten Ähnlichkeitswerte für die Satzpaare aus dem Testdatensatz mit den erwarteten Werten übereinstimmen.\n",
    "\n",
    "Dazu verwenden wir den [Korrelationskoeffizienten](https://de.wikipedia.org/wiki/Korrelationskoeffizient), der uns in ```scipy``` als [```pearsonr```](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html) zur Verfügung steht.\n",
    "\n",
    "Schreibt eine Funktion, die zwei Listen mit Ähnlichkeitswerten entgegennimmt und für diese den Pearsonscore berechnet. Wendet die Funktion auf die für die Testdaten erwarteten und die von uns berechneten Ähnlichkeitsscores an und interpretiert das Ergebnis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "def calculate_pearson_score(expected, actual):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Anwenden\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
